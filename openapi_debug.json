{"openapi":"3.1.0","info":{"title":"LangGraph Reasoning Service","description":"\n    Inference-Time Scaling with Self-Correcting Reasoning.\n\n    This service implements System 2 reasoning using:\n    - DeepSeek-R1's native <think> tokens for chain-of-thought\n    - LangGraph for stateful workflow management\n    - Self-correction loop: Reason → Critique → Refine\n\n    Designed for complex reasoning tasks that benefit from\n    deliberative, iterative problem-solving.\n    ","version":"0.1.0"},"paths":{"/v1/reason":{"post":{"summary":"Reason","description":"Submit a reasoning task with self-correction loop.\n\nThe service will:\n1. Generate initial reasoning using DeepSeek-R1's <think> tokens\n2. Critique the answer for logical errors\n3. Refine and iterate until approved or max iterations reached\n\nArgs:\n    request: The reasoning request with query and optional parameters.\n\nReturns:\n    The reasoning response with trace, final answer, and metadata.","operationId":"reason_v1_reason_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ReasoningRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ReasoningResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/health":{"get":{"summary":"Health Check","description":"Check service health and Ollama connectivity.\n\nReturns:\n    Health status including model configuration and Ollama connection state.","operationId":"health_check_health_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HealthResponse"}}}}}}},"/v1/test-inference":{"post":{"summary":"Test Inference","description":"Run a fast inference check (max 10 tokens).","operationId":"test_inference_v1_test_inference_post","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TestInferenceResponse"}}}}}}},"/api/info":{"get":{"summary":"Info","description":"Return service information.","operationId":"info_api_info_get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}},"/":{"get":{"summary":"Root","description":"Serve the UI.","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"HealthResponse":{"properties":{"status":{"type":"string","title":"Status","description":"Service health status"},"model":{"type":"string","title":"Model","description":"Configured LLM model"},"ollama_connected":{"type":"boolean","title":"Ollama Connected","description":"Whether Ollama is reachable"}},"type":"object","required":["status","model","ollama_connected"],"title":"HealthResponse","description":"Response model for health check endpoint."},"ReasoningRequest":{"properties":{"query":{"type":"string","title":"Query","description":"The question or problem to reason about","examples":["What are the implications of Godel's incompleteness theorems for AGI?"]},"max_iterations":{"anyOf":[{"type":"integer","maximum":20.0,"minimum":1.0},{"type":"null"}],"title":"Max Iterations","description":"Maximum reasoning iterations (overrides default)"},"temperature":{"anyOf":[{"type":"number","maximum":2.0,"minimum":0.0},{"type":"null"}],"title":"Temperature","description":"Sampling temperature for generation"}},"type":"object","required":["query"],"title":"ReasoningRequest","description":"Request model for submitting a reasoning task."},"ReasoningResponse":{"properties":{"query":{"type":"string","title":"Query","description":"The original query"},"reasoning_trace":{"items":{"type":"string"},"type":"array","title":"Reasoning Trace","description":"List of reasoning steps with <think> output"},"final_answer":{"type":"string","title":"Final Answer","description":"The final approved answer"},"iterations":{"type":"integer","title":"Iterations","description":"Number of reasoning iterations performed"},"is_approved":{"type":"boolean","title":"Is Approved","description":"Whether the answer was explicitly approved by critique"}},"type":"object","required":["query","reasoning_trace","final_answer","iterations","is_approved"],"title":"ReasoningResponse","description":"Response model for a completed reasoning task."},"TestInferenceResponse":{"properties":{"status":{"type":"string","title":"Status","default":"ok"},"response":{"type":"string","title":"Response"},"duration_ms":{"type":"number","title":"Duration Ms"},"model":{"type":"string","title":"Model","description":"The LLM model used for inference"}},"type":"object","required":["response","duration_ms","model"],"title":"TestInferenceResponse","description":"Response model for the fast inference test."},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"}}}}